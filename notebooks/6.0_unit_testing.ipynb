{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/rohwid/Pacmann/lazada-id-reviews/notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to the main directory\n",
    "# So, it's executed from main directory\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('.env') as f:\n",
    "    os.environ.update(\n",
    "        line.strip().split('=') for line in f\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/rohwid/Pacmann/lazada-id-reviews'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unit Testing Config\n",
    "\n",
    "This code will be apply in `src/LadazaIDReview/entity/config_entity.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class UnitTestConfig:\n",
    "    root_dir: Path\n",
    "    mlflow_tracking_uri: str\n",
    "    mlflow_model_name: str\n",
    "    mlflow_deploy_model_alias: str\n",
    "    mlflow_input_example_path: Path\n",
    "    app_endpoint: str\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unit Testing Config Manager\n",
    "\n",
    "This code will be apply in `src/LazadaIDReview/config/configurations.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LazadaIDReviews.constants import CONFIG_FILE_PATH, PARAMS_FILE_PATH\n",
    "from LazadaIDReviews.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self, \n",
    "                 config_filepath = CONFIG_FILE_PATH,\n",
    "                 params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "    \n",
    "    def get_unit_test_config(self) -> UnitTestConfig:\n",
    "        \"\"\"read training evaluation config file and store as \n",
    "        config entity then apply the dataclasses\n",
    "        \n",
    "        Returns:\n",
    "            config: UnitTestConfig type\n",
    "        \"\"\"\n",
    "        predict_config = self.config.predict\n",
    "        unit_test_config = self.config.unit_test\n",
    "\n",
    "        create_directories([unit_test_config.root_dir])\n",
    "\n",
    "        config = UnitTestConfig(\n",
    "            root_dir=unit_test_config.root_dir,\n",
    "            mlflow_tracking_uri=os.environ[\"MLFLOW_TRACKING_URI\"],\n",
    "            mlflow_model_name=predict_config.mlflow_model_name,\n",
    "            mlflow_deploy_model_alias=os.environ[\"MLFLOW_DEPLOY_MODEL_ALIAS\"],\n",
    "            mlflow_input_example_path=unit_test_config.mlflow_input_example_path,\n",
    "            app_endpoint=os.environ[\"APP_ENDPOINT\"]\n",
    "        )\n",
    "\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.artifacts import download_artifacts\n",
    "from mlflow import MlflowClient\n",
    "from mlflow import pyfunc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Debug**: Explain when doing the preparation test in the notebook with MLflow like load input example and etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-03 22:52:00,744: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
      "[2024-07-03 22:52:00,747: INFO: common: yaml file: metrics/params.yaml loaded successfully]\n",
      "[2024-07-03 22:52:00,748: INFO: common: created directory at: artifacts]\n",
      "[2024-07-03 22:52:00,750: INFO: common: created directory at: artifacts/test]\n"
     ]
    }
   ],
   "source": [
    "config = ConfigurationManager()\n",
    "unit_test_config = config.get_unit_test_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the deployed model from MLflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mlflow-artifacts:/1/7c4369e2226e46f993302aec56b059ac/artifacts/models'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = MlflowClient(tracking_uri=unit_test_config.mlflow_tracking_uri)\n",
    "selected_model = client.get_model_version_by_alias(\n",
    "    unit_test_config.mlflow_model_name, \n",
    "    unit_test_config.mlflow_deploy_model_alias\n",
    ")\n",
    "\n",
    "selected_model.source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47a6d5d94ee74ef8a59054d115e81c49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "mlflow.pyfunc.loaded_model:\n",
       "  artifact_path: models\n",
       "  flavor: mlflow.sklearn\n",
       "  run_id: 7c4369e2226e46f993302aec56b059ac"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = pyfunc.load_model(model_uri=selected_model.source)\n",
    "loaded_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the model `run_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7c4369e2226e46f993302aec56b059ac'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_run_id = selected_model.run_id\n",
    "selected_run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e648bb43628f4238a0ed8414106300f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'/home/rohwid/Pacmann/lazada-id-reviews/artifacts/test/models/input_example.json'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_artifacts(\n",
    "    run_id=selected_run_id,\n",
    "    artifact_path=unit_test_config.mlflow_input_example_path,\n",
    "    dst_path=unit_test_config.root_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'columns': ['reviewContents'],\n",
       " 'data': [[['mantul',\n",
       "    'pengiriman super cepat',\n",
       "    'flashdisk rusak tdk bs menyimpan...barang baru tp rusak',\n",
       "    'barang berfungsi normal...semoga awet...',\n",
       "    'bagus dan cepat',\n",
       "    'Alhamdulillah sampai dgn selamat tapi y kekurangannya pindahin chanel lambat',\n",
       "    'lumyan bagus',\n",
       "    'Bagus...real kapasitasnya...sebelumnya beli yg kapasitas 32 gb....',\n",
       "    'pengiriman cpt kmrn bayar besok dtng top dah puas semoga awet tv nya',\n",
       "    'kapasitas tersisa 29.80GB. Berfungsi baik. pengiriman \"disediakan oleh lazada\" cepat sampai.']]]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "f = open(f\"{unit_test_config.root_dir}/{unit_test_config.mlflow_input_example_path}\")\n",
    "input_example = json.load(f)\n",
    "input_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the input data from MLflow input examples and try to match with the MLflow input example format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reviewContents': ['mantul',\n",
       "  'pengiriman super cepat',\n",
       "  'flashdisk rusak tdk bs menyimpan...barang baru tp rusak',\n",
       "  'barang berfungsi normal...semoga awet...',\n",
       "  'bagus dan cepat',\n",
       "  'Alhamdulillah sampai dgn selamat tapi y kekurangannya pindahin chanel lambat',\n",
       "  'lumyan bagus',\n",
       "  'Bagus...real kapasitasnya...sebelumnya beli yg kapasitas 32 gb....',\n",
       "  'pengiriman cpt kmrn bayar besok dtng top dah puas semoga awet tv nya',\n",
       "  'kapasitas tersisa 29.80GB. Berfungsi baik. pengiriman \"disediakan oleh lazada\" cepat sampai.']}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "request_body = {\n",
    "    input_example[\"columns\"][0]: input_example['data'][0][0]\n",
    "}\n",
    "\n",
    "request_body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the `app.py` with http request with MLflow input data example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "result = requests.post(url=unit_test_config.app_endpoint, json=request_body)\n",
    "y_predict = result.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 5, 1, 4, 5, 4, 4, 2, 5, 4]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Unit Testing\n",
    "\n",
    "This code in `src/LazadaIDReview/components/unit_testing.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "from LazadaIDReviews import logger\n",
    "\n",
    "class UnitTesting:\n",
    "    def __init__(self, config: UnitTestConfig):\n",
    "        self.config = config\n",
    "        self.req_body_key = None\n",
    "        self.req_body = None\n",
    "    \n",
    "    def set_request_body(self) -> None:\n",
    "        \"\"\"predict the data with linear regression model\n",
    "\n",
    "        Raises:\n",
    "            client_error: error when access mlflow to get deployed model\n",
    "            download_error: error when download vectorizer from mlflow artifact\n",
    "        \"\"\"\n",
    "        try:\n",
    "            logger.info(\"Set MLflow Client.\")\n",
    "            client = MlflowClient(tracking_uri=self.config.mlflow_tracking_uri)\n",
    "            selected_model = client.get_model_version_by_alias(\n",
    "                self.config.mlflow_model_name, \n",
    "                self.config.mlflow_deploy_model_alias\n",
    "            )\n",
    "            \n",
    "            logger.info(\"Get the deployed model run id.\")\n",
    "            selected_run_id = selected_model.run_id\n",
    "        except Exception as client_error:\n",
    "            logger.error(client_error)\n",
    "            raise client_error\n",
    "\n",
    "        try:\n",
    "            logger.info(\"Downloading vectorizer from MLflow's artifacts.\")\n",
    "            download_artifacts(\n",
    "                run_id=selected_run_id,\n",
    "                artifact_path=self.config.mlflow_input_example_path,\n",
    "                dst_path=self.config.root_dir\n",
    "            )\n",
    "        except Exception as download_error:\n",
    "            logger.error(download_error)\n",
    "            raise download_error\n",
    "        \n",
    "        logger.info(\"Open MLflow input example.\")\n",
    "        f = open(f\"{self.config.root_dir}/{self.config.mlflow_input_example_path}\")\n",
    "        input_example = json.load(f)\n",
    "\n",
    "        # handle mlflow input example data\n",
    "        data_key = input_example[\"columns\"][0]\n",
    "        data_val = input_example['data'][0][0]\n",
    "\n",
    "        # request params\n",
    "        self.req_body_key = data_key\n",
    "        self.req_body = {\n",
    "            data_key: data_val\n",
    "        }\n",
    "        \n",
    "    def get_request_body_value(self) -> list:\n",
    "        \"\"\"get the request body data\n",
    "\n",
    "        Returns:\n",
    "            req_body: list type\n",
    "        \"\"\"\n",
    "        logger.info(\"Get MLflow input example value.\")\n",
    "        req_body_value = self.req_body[self.req_body_key]\n",
    "        return req_body_value\n",
    "    \n",
    "    def get_output_length(self):\n",
    "        \"\"\"get the output length of the predict result\n",
    "\n",
    "        Returns:\n",
    "            len_result: list type\n",
    "        \"\"\"\n",
    "        logger.info(\"Get predicted result length.\")\n",
    "        result = requests.post(\n",
    "            url=self.config.app_endpoint, \n",
    "            json=self.req_body\n",
    "        )\n",
    "        len_result = len(result.json())\n",
    "        return len_result\n",
    "\n",
    "    def is_output_type_list(self) -> bool:\n",
    "        \"\"\"check if the output file is list data type\n",
    "\n",
    "        Returns:\n",
    "            is_list: bool type\n",
    "        \"\"\"\n",
    "        logger.info(\"Check is the predicted output is list.\")\n",
    "        result = requests.post(\n",
    "            url=self.config.app_endpoint, \n",
    "            json=self.req_body\n",
    "        )\n",
    "        is_list = type(result.json()) is list\n",
    "        return is_list\n",
    "\n",
    "    def is_output_type_consistent(self) -> bool:\n",
    "        \"\"\"check if the output file have consistent\n",
    "        data type inside a list\n",
    "\n",
    "        Returns:\n",
    "            bool type\n",
    "        \"\"\"\n",
    "        logger.info(\"Check is each predicted output is integer\")\n",
    "        result = requests.post(\n",
    "            url=self.config.app_endpoint, \n",
    "            json=self.req_body\n",
    "        )\n",
    "        for result in result.json():\n",
    "            if type(result) is not int:\n",
    "                return False\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Testing\n",
    "\n",
    "**Debug**: Simulate the unit testing without library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-03 22:57:17,947: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
      "[2024-07-03 22:57:17,949: INFO: common: yaml file: metrics/params.yaml loaded successfully]\n",
      "[2024-07-03 22:57:17,950: INFO: common: created directory at: artifacts]\n",
      "[2024-07-03 22:57:17,952: INFO: common: created directory at: artifacts/test]\n",
      "[2024-07-03 22:57:17,952: INFO: 1595305458: Set MLflow Client.]\n",
      "[2024-07-03 22:57:18,215: INFO: 1595305458: Get the deployed model run id.]\n",
      "[2024-07-03 22:57:18,216: INFO: 1595305458: Downloading vectorizer from MLflow's artifacts.]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2e5b45e5c704230b6aaeb0ceb4853d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-03 22:57:19,129: INFO: 1595305458: Open MLflow input example.]\n",
      "Review Contents: \n",
      "[2024-07-03 22:57:19,132: INFO: 1595305458: Get MLflow input example value.]\n",
      "mantul\n",
      "pengiriman super cepat\n",
      "flashdisk rusak tdk bs menyimpan...barang baru tp rusak\n",
      "barang berfungsi normal...semoga awet...\n",
      "bagus dan cepat\n",
      "Alhamdulillah sampai dgn selamat tapi y kekurangannya pindahin chanel lambat\n",
      "lumyan bagus\n",
      "Bagus...real kapasitasnya...sebelumnya beli yg kapasitas 32 gb....\n",
      "pengiriman cpt kmrn bayar besok dtng top dah puas semoga awet tv nya\n",
      "kapasitas tersisa 29.80GB. Berfungsi baik. pengiriman \"disediakan oleh lazada\" cepat sampai.\n",
      "\n",
      "Begin tests:\n",
      "[2024-07-03 22:57:19,133: INFO: 1595305458: Get predicted result length.]\n",
      "[2024-07-03 22:57:22,682: INFO: 1595305458: Get MLflow input example value.]\n",
      "Is same size: True\n",
      "[2024-07-03 22:57:22,683: INFO: 1595305458: Check is the predicted output is list.]\n",
      "Is the output is list: True\n",
      "[2024-07-03 22:57:26,262: INFO: 1595305458: Check is each predicted output is integer]\n",
      "Is the output consistent: True\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    unit_testing_config = config.get_unit_test_config()\n",
    "    unit_test = UnitTesting(config=unit_testing_config)\n",
    "    unit_test.set_request_body()\n",
    "    \n",
    "    print(\"Review Contents: \")\n",
    "    for content in unit_test.get_request_body_value():\n",
    "        print(content)\n",
    "    \n",
    "    print(\"\\nBegin tests:\")\n",
    "    print(f\"Is same size: {unit_test.get_output_length() == len(unit_test.get_request_body_value())}\")\n",
    "    print(f\"Is the output is list: {unit_test.is_output_type_list() == True}\")\n",
    "    print(f\"Is the output consistent: {unit_test.is_output_type_consistent() == True}\")\n",
    "except Exception as e:\n",
    "    logger.error(e)\n",
    "    raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".lazada-id-reviews-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
