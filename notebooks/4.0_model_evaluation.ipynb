{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/rohwid/Pacmann/lazada-id-reviews/notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to the main directory\n",
    "# So, it's executed from main directory\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('.env') as f:\n",
    "    os.environ.update(\n",
    "        line.strip().split('=') for line in f\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/rohwid/Pacmann/lazada-id-reviews'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Config\n",
    "\n",
    "This code will be apply in `src/LadazaIDReviews/entity/config_entity.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class TrainEvaluationConfig:\n",
    "    root_dir: Path\n",
    "    input_train_path: Path\n",
    "    input_test_path: Path\n",
    "    output_train_path: Path\n",
    "    output_test_path: Path\n",
    "    vectorized_train_path: Path\n",
    "    vectorized_test_path: Path\n",
    "    vectorizer_model_path: Path\n",
    "    model_path: Path\n",
    "    score_path: Path\n",
    "    mlflow_dataset_path: Path\n",
    "    mlflow_dataset_column: list\n",
    "    minio_endpoint_url: str\n",
    "    minio_access_key_id: str\n",
    "    minio_secret_access_key: str\n",
    "    mlflow_tracking_uri: str\n",
    "    mlflow_exp_name: str\n",
    "    mlflow_dataset_bucket: str\n",
    "    mlflow_run_name: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Config Manager\n",
    "\n",
    "This code will be apply in `src/LazadaIDReviews/config/configurations.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LazadaIDReviews.constants import CONFIG_FILE_PATH, PARAMS_FILE_PATH\n",
    "from LazadaIDReviews.utils.common import read_yaml, create_directories, save_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self, \n",
    "                 config_filepath = CONFIG_FILE_PATH,\n",
    "                 params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "    \n",
    "    def get_train_eval_config(self) -> TrainEvaluationConfig:\n",
    "        \"\"\"read training evaluation config file and store as \n",
    "        config entity then apply the dataclasses\n",
    "        \n",
    "        Returns:\n",
    "            config: TrainEvaluationConfig type\n",
    "        \"\"\"\n",
    "        data_dump_config = self.config.dump_data\n",
    "        vectorize_config = self.config.vectorize_data\n",
    "        train_config = self.config.train_model\n",
    "        eval_config = self.config.train_evaluation\n",
    "\n",
    "        create_directories([eval_config.root_dir])\n",
    "\n",
    "        config = TrainEvaluationConfig(\n",
    "            root_dir=eval_config.root_dir,\n",
    "            input_train_path=Path(data_dump_config.input_train_path),\n",
    "            input_test_path=Path(data_dump_config.input_test_path),\n",
    "            output_train_path=Path(data_dump_config.output_train_path),\n",
    "            output_test_path=Path(data_dump_config.output_test_path),\n",
    "            vectorized_train_path=Path(vectorize_config.vectorized_train_path),\n",
    "            vectorized_test_path=Path(vectorize_config.vectorized_test_path),\n",
    "            vectorizer_model_path=Path(vectorize_config.vectorizer_model_path),\n",
    "            model_path=Path(train_config.model_path),\n",
    "            score_path=Path(eval_config.score_path),\n",
    "            mlflow_dataset_path=Path(eval_config.mlflow_dataset_path),\n",
    "            mlflow_dataset_column=eval_config.mlflow_dataset_column,\n",
    "            minio_endpoint_url=os.environ['MLFLOW_S3_ENDPOINT_URL'],\n",
    "            minio_access_key_id=os.environ['AWS_ACCESS_KEY_ID'],\n",
    "            minio_secret_access_key=os.environ['AWS_SECRET_ACCESS_KEY'],\n",
    "            mlflow_tracking_uri=os.environ[\"MLFLOW_TRACKING_URI\"],\n",
    "            mlflow_exp_name=eval_config.mlflow_exp_name,\n",
    "            mlflow_dataset_bucket=os.environ[\"PROJECT_BUCKET\"],\n",
    "            mlflow_run_name=eval_config.mlflow_run_name\n",
    "        )\n",
    "\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config in `src/LazadaIDReviews/components/model_evaluation.py`\n",
    "\n",
    "Logging is tied with a runs, which is **one cycle training and evaluating model**.\n",
    "To start logging, we have to give mlflow **a context**, which is our **current run**.\n",
    "\n",
    "Steps:\n",
    "+ Load train and test data (text and vectorized), its target data, and the vectorizer.\n",
    "+ Pointing the mlflow client in our program to our mlflow server.\n",
    "+ Set experiment.\n",
    "+ Set MLflow to run and start logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import joblib\n",
    "import mlflow\n",
    "import string\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "from mlflow.data.pandas_dataset import PandasDataset\n",
    "from mlflow.data.dataset_source import DatasetSource\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from LazadaIDReviews import logger\n",
    "\n",
    "class TrainEvaluation:\n",
    "    def __init__(self, config: TrainEvaluationConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def get_prediction(self, model, X_input_vec, X_input) -> pd.DataFrame:\n",
    "        \"\"\"predict the input data with the model\n",
    "        \n",
    "        Args:\n",
    "            model (Any): the machine learning model\n",
    "            X_input_vec (Any): the vectorized input data\n",
    "            X_input (pd.Series): the input data\n",
    "        \n",
    "        Returns:\n",
    "            pd.Dataframe: prediction result in dataframe\n",
    "        \"\"\"\n",
    "        y_predict = pd.Series(model.predict(X_input_vec), index = X_input.index)\n",
    "        \n",
    "        return y_predict\n",
    "    \n",
    "    def get_report(self, y_output, y_predict) -> dict:\n",
    "        \"\"\"generate the classification report and dump the report as json\n",
    "        \n",
    "        Args:\n",
    "            y_output (pd.Series): the actual output data\n",
    "            y_predict (pd.Series): the prediction result\n",
    "        \n",
    "        Returns:\n",
    "            dict: classification report in dict format\n",
    "        \"\"\"\n",
    "        metrics = classification_report(y_output, y_predict, output_dict=True)\n",
    "        \n",
    "        logger.info(f\"Save report as json.\")\n",
    "        save_json(path=self.config.score_path, data=metrics)\n",
    "        \n",
    "        logger.info(f\"Show the training report.\")\n",
    "        print(f\"\\n{classification_report(y_output, y_predict)}\")\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def get_mlflow_metrics(self, metrics) -> dict:\n",
    "        \"\"\"generate the classification report for MLflow\n",
    "\n",
    "        Args:\n",
    "            metrics (dict): the classification report\n",
    "        \n",
    "        Returns:\n",
    "            dict: classification report in dict format\n",
    "        \"\"\"\n",
    "        mlflow_metrics = {}\n",
    "\n",
    "        for rating in range(len(metrics) - 3):\n",
    "            data_metric = metrics[str(rating + 1)]\n",
    "            for name, value in data_metric.items():\n",
    "                mlflow_metrics[name + \"_\" + str(rating + 1)] = value\n",
    "        \n",
    "        return mlflow_metrics\n",
    "    \n",
    "    def get_dataset(self, X_input, y_output, y_predict) -> pd.DataFrame:\n",
    "        \"\"\"construct the dataset and save as dataframe and csv file\n",
    "        \n",
    "        Args:\n",
    "            X_input (pd.Series): the input data\n",
    "            y_output (pd.Series): the actual output data\n",
    "            y_predict (pd.Series): the prediction result\n",
    "        \n",
    "        Returns:\n",
    "            pd.Dataframe: prediction result in dataframe\n",
    "        \"\"\"\n",
    "        train_eval_result = pd.concat([X_input, y_output, y_predict], axis = 1)\n",
    "        train_eval_result.columns = self.config.mlflow_dataset_column\n",
    "        train_eval_result.to_csv(self.config.mlflow_dataset_path, index=False)\n",
    "        \n",
    "        return train_eval_result\n",
    "        \n",
    "    def get_mlflow_dataset(self, mlflow_dataset, run_name) -> PandasDataset:\n",
    "        \"\"\"convert the dataset into MLflow's dataset format\n",
    "        \n",
    "        Args:\n",
    "            mlflow_dataset (pd.Series): the project dataset to train and the result\n",
    "            run_name (str): the name of MLflow runs\n",
    "        \n",
    "        Returns:\n",
    "            PandasDataset: the dataset in Pandas MLflow format\n",
    "        \"\"\"\n",
    "        mlflow_dataset: PandasDataset=mlflow.data.from_pandas(\n",
    "            mlflow_dataset,\n",
    "            source=DatasetSource.load(f\"s3://{self.config.mlflow_dataset_bucket}/{run_name}.csv\"),\n",
    "            name=f\"{run_name}\",\n",
    "            targets=self.config.mlflow_dataset_column[1],\n",
    "            predictions=self.config.mlflow_dataset_column[2]\n",
    "        )\n",
    "        \n",
    "        logger.info(f\"Remove {self.config.mlflow_dataset_path} file from local.\")\n",
    "        os.remove(self.config.mlflow_dataset_path)\n",
    "        \n",
    "        return mlflow_dataset\n",
    "    \n",
    "    def s3_upload_mlflow_dataset(self, run_name) -> None:\n",
    "        \"\"\"upload the dataset into MinIO with MLflow run_name\n",
    "        \n",
    "        Args:\n",
    "            run_name (str): the name of MLflow runs\n",
    "        \"\"\"\n",
    "        s3 = boto3.client('s3',\n",
    "                              endpoint_url=self.config.minio_endpoint_url,\n",
    "                              aws_access_key_id=self.config.minio_access_key_id,\n",
    "                              aws_secret_access_key=self.config.minio_secret_access_key)\n",
    "        \n",
    "        try:\n",
    "            s3.upload_file(\n",
    "                self.config.mlflow_dataset_path, \n",
    "                self.config.mlflow_dataset_bucket, \n",
    "                f'{run_name}.csv'\n",
    "            )    \n",
    "        except Exception as e:\n",
    "            logger.error(e)\n",
    "            raise e\n",
    "    \n",
    "    def mlflow_log_train(self) -> None:\n",
    "        \"\"\"perform experimentation with MLflow to evaluate the training result\n",
    "        \"\"\"\n",
    "        logger.info(f\"Load vectorized data train from {self.config.vectorized_train_path}.\")\n",
    "        X_train_vec = joblib.load(self.config.vectorized_train_path)\n",
    "        # X_test_vec = joblib.load(self.config.vectorized_test_path)\n",
    "        \n",
    "        logger.info(f\"Load data train from {self.config.input_train_path}.\")\n",
    "        X_train = joblib.load(self.config.input_train_path)\n",
    "        X_test = joblib.load(self.config.input_test_path)\n",
    "        \n",
    "        logger.info(f\"Load data train output from {self.config.output_train_path}.\")\n",
    "        y_train = joblib.load(self.config.output_train_path)\n",
    "        # y_test = joblib.load(self.config.output_test_path)\n",
    "        \n",
    "        logger.info(f\"Load the model.\")\n",
    "        model = joblib.load(self.config.model_path)\n",
    "        \n",
    "        logger.info(f\"Predicting the data train.\")\n",
    "        y_train_pred = self.get_prediction(model, X_train_vec, X_train)\n",
    "        \n",
    "        logger.info(f\"Generate classification report.\")\n",
    "        train_report = self.get_report(y_train, y_train_pred)\n",
    "        \n",
    "        logger.info(f\"Set tracking URI.\")\n",
    "        mlflow.set_tracking_uri(self.config.mlflow_tracking_uri)\n",
    "        \n",
    "        logger.info(f\"Set experiment name.\")\n",
    "        mlflow.set_experiment(self.config.mlflow_exp_name)\n",
    "        \n",
    "        logger.info(f\"Set run name.\")\n",
    "        flag = ''.join(random.choices(\n",
    "            string.ascii_uppercase + string.ascii_lowercase + string.digits, \n",
    "            k=5))\n",
    "        run_name = f\"{self.config.mlflow_run_name}-{flag}\"\n",
    "        \n",
    "        logger.info(f\"Contruct report for MLflow.\")\n",
    "        mlflow_metrics = self.get_mlflow_metrics(train_report)\n",
    "        \n",
    "        logger.info(f\"Contruct MLflow dataset file in {self.config.mlflow_dataset_path}.\")\n",
    "        mlflow_train_dataset = self.get_dataset(X_train, y_train, y_train_pred)\n",
    "\n",
    "        logger.info(f\"Contruct MLflow input example\")\n",
    "        sample = 10\n",
    "        input_example = {\"reviewContents\": X_test.to_list()[:sample]}\n",
    "\n",
    "        logger.info(f\"Experiement tracking to evaluate model with MLflow.\")\n",
    "        with mlflow.start_run(run_name=run_name):\n",
    "            logger.info(f\"Upload {self.config.mlflow_dataset_path} file to MinIO.\")\n",
    "            self.s3_upload_mlflow_dataset(run_name)\n",
    "            \n",
    "            logger.info(f\"Set MLflow dataset.\")\n",
    "            dataset = self.get_mlflow_dataset(mlflow_train_dataset, run_name)\n",
    "\n",
    "            logger.info(f\"Logging to MLflow as an experiment.\")\n",
    "            model_params = model.get_params()\n",
    "            mlflow.log_params(model_params)\n",
    "            mlflow.log_metrics(mlflow_metrics)\n",
    "            mlflow.log_input(dataset, context=\"training\")\n",
    "            mlflow.log_artifact(self.config.vectorizer_model_path, \"vectorizer\")\n",
    "            mlflow.sklearn.log_model(\n",
    "                sk_model=model,\n",
    "                artifact_path=\"models\",\n",
    "                serialization_format=mlflow.sklearn.SERIALIZATION_FORMAT_CLOUDPICKLE,\n",
    "                registered_model_name=\"logistic_regression\",\n",
    "                input_example=input_example\n",
    "            )\n",
    "            \n",
    "            mlflow.set_tags(\n",
    "                {\n",
    "                    \"dataset\": \"review contents training dataset and prediction result\",\n",
    "                    \"model\": \"logistic_regression\"\n",
    "                }\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-03 22:01:55,973: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
      "[2024-07-03 22:01:55,977: INFO: common: yaml file: metrics/params.yaml loaded successfully]\n",
      "[2024-07-03 22:01:55,978: INFO: common: created directory at: artifacts]\n",
      "[2024-07-03 22:01:55,981: INFO: common: created directory at: artifacts/models]\n",
      "[2024-07-03 22:01:55,982: INFO: 446721534: Load vectorized data train from artifacts/preprocessing/X_train_vec.pkl.]\n",
      "[2024-07-03 22:01:55,991: INFO: 446721534: Load data train from artifacts/data/X_train.pkl.]\n",
      "[2024-07-03 22:01:56,216: INFO: 446721534: Load data train output from artifacts/data/y_train.pkl.]\n",
      "[2024-07-03 22:01:56,219: INFO: 446721534: Load the model.]\n",
      "[2024-07-03 22:01:56,251: INFO: 446721534: Predicting the data train.]\n",
      "[2024-07-03 22:01:56,266: INFO: 446721534: Generate classification report.]\n",
      "[2024-07-03 22:01:56,333: INFO: 446721534: Save report as json.]\n",
      "[2024-07-03 22:01:56,335: INFO: common: json file saved at: metrics/scores.json]\n",
      "[2024-07-03 22:01:56,337: INFO: 446721534: Show the training report.]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.96      0.97      0.97     16711\n",
      "           2       0.97      0.99      0.98     16711\n",
      "           3       0.92      0.91      0.92     16711\n",
      "           4       0.85      0.82      0.84     16711\n",
      "           5       0.79      0.79      0.79     16711\n",
      "\n",
      "    accuracy                           0.90     83555\n",
      "   macro avg       0.90      0.90      0.90     83555\n",
      "weighted avg       0.90      0.90      0.90     83555\n",
      "\n",
      "[2024-07-03 22:01:56,413: INFO: 446721534: Set tracking URI.]\n",
      "[2024-07-03 22:01:56,415: INFO: 446721534: Set experiment name.]\n",
      "[2024-07-03 22:01:56,725: INFO: 446721534: Set run name.]\n",
      "[2024-07-03 22:01:56,728: INFO: 446721534: Contruct report for MLflow.]\n",
      "[2024-07-03 22:01:56,730: INFO: 446721534: Contruct MLflow dataset file in artifacts/data/train_eval_result.csv.]\n",
      "[2024-07-03 22:01:56,949: INFO: 446721534: Contruct MLflow input example]\n",
      "[2024-07-03 22:01:56,952: INFO: 446721534: Experiement tracking to evaluate model with MLflow.]\n",
      "[2024-07-03 22:01:57,303: INFO: 446721534: Upload artifacts/data/train_eval_result.csv file to MinIO.]\n",
      "[2024-07-03 22:02:04,932: INFO: 446721534: Set MLflow dataset.]\n",
      "[2024-07-03 22:02:04,980: INFO: 446721534: Remove artifacts/data/train_eval_result.csv file from local.]\n",
      "[2024-07-03 22:02:04,983: INFO: 446721534: Logging to MLflow as an experiment.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rohwid/Pacmann/lazada-id-reviews/.lazada-reviews-venv/lib/python3.10/site-packages/mlflow/types/utils.py:394: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "2024/07/03 22:02:31 INFO mlflow.models.utils: We convert input dictionaries to pandas DataFrames such that each key represents a column, collectively constituting a single row of data. If you would like to save data as multiple rows, please convert your data to a pandas DataFrame before passing to input_example.\n",
      "/home/rohwid/Pacmann/lazada-id-reviews/.lazada-reviews-venv/lib/python3.10/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "2024/07/03 22:02:31 WARNING mlflow.models.signature: Failed to infer the model signature from the input example. Reason: ValueError('setting an array element with a sequence.'). To see the full traceback, set the logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)`. To disable automatic signature inference, set `signature` to `False` in your `log_model` or `save_model` call.\n",
      "2024/07/03 22:02:31 INFO mlflow.models.utils: We convert input dictionaries to pandas DataFrames such that each key represents a column, collectively constituting a single row of data. If you would like to save data as multiple rows, please convert your data to a pandas DataFrame before passing to input_example.\n",
      "Registered model 'logistic_regression' already exists. Creating a new version of this model...\n",
      "2024/07/03 22:02:38 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: logistic_regression, version 4\n",
      "Created version '4' of model 'logistic_regression'.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    eval_config = config.get_train_eval_config()\n",
    "    evaluation = TrainEvaluation(config=eval_config)\n",
    "    evaluation.mlflow_log_train()\n",
    "except Exception as e:\n",
    "    logger.error(e)\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Debug**: Check the dataset in MLflow and MinIO\n",
    "\n",
    "by checking the MLflow last active run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset name: train-eval-gERE0\n",
      "Dataset digest: 406ae510\n",
      "Dataset profile: {\"num_rows\": 83555, \"num_elements\": 250665}\n",
      "Dataset schema: {\"mlflow_colspec\": [{\"type\": \"string\", \"name\": \"reviewContents\", \"required\": true}, {\"type\": \"long\", \"name\": \"ratings\", \"required\": true}, {\"type\": \"long\", \"name\": \"predictions\", \"required\": true}]}\n"
     ]
    }
   ],
   "source": [
    "run = mlflow.get_run(mlflow.last_active_run().info.run_id)\n",
    "dataset_info = run.inputs.dataset_inputs[0].dataset\n",
    "print(f\"Dataset name: {dataset_info.name}\")\n",
    "print(f\"Dataset digest: {dataset_info.digest}\")\n",
    "print(f\"Dataset profile: {dataset_info.profile}\")\n",
    "print(f\"Dataset schema: {dataset_info.schema}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-03 22:02:40,015: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
      "[2024-07-03 22:02:40,018: INFO: common: yaml file: metrics/params.yaml loaded successfully]\n",
      "[2024-07-03 22:02:40,019: INFO: common: created directory at: artifacts]\n",
      "[2024-07-03 22:02:40,022: INFO: common: created directory at: artifacts/models]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    eval_config = config.get_train_eval_config()\n",
    "\n",
    "    s3 = boto3.client('s3',\n",
    "                    endpoint_url=eval_config.minio_endpoint_url,\n",
    "                    aws_access_key_id=eval_config.minio_access_key_id,\n",
    "                    aws_secret_access_key=eval_config.minio_secret_access_key)\n",
    "\n",
    "    obj = s3.get_object(Bucket=eval_config.mlflow_dataset_bucket, Key=f\"{dataset_info.name}.csv\") \n",
    "    df = pd.read_csv(obj['Body'])\n",
    "except Exception as e:\n",
    "    logger.error(e)\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewContents</th>\n",
       "      <th>ratings</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>persen kemarin sore ...jam 2 siang datang...ga...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dah sampai... nyobanya nunggu pulang kerja... ...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recommended seller..</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pengiriman cepat sekali 2 hari sampai, packing...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>iish..keren pisaan.. kuy laen beli.. gak akan ...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83550</th>\n",
       "      <td>Produk sesuai dengan yang ditawarkan Kendala h...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83551</th>\n",
       "      <td>fast respon 2hari smpe...tv nya bgus</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83552</th>\n",
       "      <td>sesuai deskripsi produk</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83553</th>\n",
       "      <td>bagus</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83554</th>\n",
       "      <td>Compatible  buat linux ga ?</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83555 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewContents  ratings  predictions\n",
       "0      persen kemarin sore ...jam 2 siang datang...ga...        5            5\n",
       "1      dah sampai... nyobanya nunggu pulang kerja... ...        5            5\n",
       "2                                   Recommended seller..        5            5\n",
       "3      Pengiriman cepat sekali 2 hari sampai, packing...        5            5\n",
       "4      iish..keren pisaan.. kuy laen beli.. gak akan ...        5            5\n",
       "...                                                  ...      ...          ...\n",
       "83550  Produk sesuai dengan yang ditawarkan Kendala h...        4            4\n",
       "83551               fast respon 2hari smpe...tv nya bgus        4            4\n",
       "83552                            sesuai deskripsi produk        4            5\n",
       "83553                                              bagus        4            5\n",
       "83554                        Compatible  buat linux ga ?        4            4\n",
       "\n",
       "[83555 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 83555 entries, 0 to 83554\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   reviewContents  83555 non-null  object\n",
      " 1   ratings         83555 non-null  int64 \n",
      " 2   predictions     83555 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".lazada-id-reviews-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
