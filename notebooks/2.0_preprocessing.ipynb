{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/rohwid/Pacmann/lazada-id-reviews/notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to the main directory\n",
    "# So, it's executed from main directory\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/rohwid/Pacmann/lazada-id-reviews'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing Config\n",
    "\n",
    "This code will be apply in `src/LadazaIDReviews/entity/config_entity.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataDumpConfig:\n",
    "    root_dir: Path\n",
    "    reviews_path: Path\n",
    "    input_train_path: Path\n",
    "    input_test_path: Path\n",
    "    output_train_path: Path\n",
    "    output_test_path: Path\n",
    "    params_test_size: float\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataPreprocessingConfig:\n",
    "    root_dir: Path\n",
    "    input_train_path: Path\n",
    "    input_test_path: Path\n",
    "    vectorized_train_path: Path\n",
    "    vectorized_test_path: Path\n",
    "    model_dir: Path\n",
    "    vectorizer_model_path: Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing Config Manager\n",
    "\n",
    "This code will be apply in `src/LazadaIDReviews/config/configurations.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we would do?\n",
    "+ Drop null values\n",
    "+ Splitting the dataset to train and test data\n",
    "+ Vectorize text using `TFIDF`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated before; let’s load, select columns, and drop null values from dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LazadaIDReviews.constants import CONFIG_FILE_PATH, PARAMS_FILE_PATH\n",
    "from LazadaIDReviews.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self, \n",
    "                 config_filepath = CONFIG_FILE_PATH,\n",
    "                 params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "    \n",
    "    def get_dump_data_config(self) -> DataDumpConfig:\n",
    "        \"\"\"read data dump config file and store as config entity\n",
    "        then apply the dataclasses\n",
    "        \n",
    "        Returns:\n",
    "            config: PreprocessingConfig type\n",
    "        \"\"\"\n",
    "        data_ingest_config = self.config.ingest_from_sql\n",
    "        data_dump_config = self.config.dump_data\n",
    "        dataset_params = self.params\n",
    "\n",
    "        create_directories([data_dump_config.root_dir])\n",
    "\n",
    "        config = DataDumpConfig(\n",
    "            root_dir=data_dump_config.root_dir,\n",
    "            reviews_path=data_ingest_config.reviews_path,\n",
    "            input_train_path=data_dump_config.input_train_path,\n",
    "            input_test_path=data_dump_config.input_test_path,\n",
    "            output_train_path=data_dump_config.output_train_path,\n",
    "            output_test_path=data_dump_config.output_test_path,\n",
    "            params_test_size=dataset_params.TEST_SIZE\n",
    "        )\n",
    "\n",
    "        return config\n",
    "    \n",
    "    def get_preprocessing_data_config(self) -> DataPreprocessingConfig:\n",
    "        \"\"\"read preprocessing config file and store as config entity\n",
    "        then apply the dataclasses\n",
    "        \n",
    "        Returns:\n",
    "            config: PreprocessingConfig type\n",
    "        \"\"\"\n",
    "        data_dump_config = self.config.dump_data\n",
    "        vectorize_config = self.config.vectorize_data\n",
    "        train_config = self.config.train_model\n",
    "\n",
    "        create_directories([vectorize_config.root_dir])\n",
    "\n",
    "        config = DataPreprocessingConfig(\n",
    "            root_dir=vectorize_config.root_dir,\n",
    "            input_train_path=Path(data_dump_config.input_train_path),\n",
    "            input_test_path=Path(data_dump_config.input_test_path),\n",
    "            vectorized_train_path=Path(vectorize_config.vectorized_train_path),\n",
    "            vectorized_test_path=Path(vectorize_config.vectorized_test_path),\n",
    "            model_dir=train_config.root_dir,\n",
    "            vectorizer_model_path=Path(vectorize_config.vectorizer_model_path)\n",
    "        )\n",
    "\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Preprocessing\n",
    "\n",
    "This code in `src/LazadaIDReviews/components/preprocessing.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from LazadaIDReviews import logger\n",
    "\n",
    "class Preprocessing:\n",
    "    def __init__(self, config: DataDumpConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def dump_data(self) -> None:\n",
    "        \"\"\"dump the splited dataset to data training and testing\n",
    "        \"\"\"\n",
    "        logger.info(f\"Read reviews file.\")\n",
    "        dataset_reviews = pd.read_csv(self.config.reviews_path)\n",
    "        dataset = dataset_reviews[[\"rating\", \"reviewContent\"]].copy()\n",
    "        dataset.dropna(inplace=True)\n",
    "        \n",
    "        logger.info(f\"Split reviews file to data train and test.\")\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            dataset[\"reviewContent\"], \n",
    "            dataset[\"rating\"], \n",
    "            test_size=self.config.params_test_size\n",
    "        )\n",
    "        \n",
    "        logger.info(f\"Dump data train into {self.config.input_train_path} directory.\")\n",
    "        X_train.to_pickle(self.config.input_train_path)\n",
    "        X_test.to_pickle(self.config.input_test_path)\n",
    "        \n",
    "        logger.info(f\"Dump data test into {self.config.input_test_path} directory.\")\n",
    "        y_train.to_pickle(self.config.output_train_path)\n",
    "        y_test.to_pickle(self.config.output_test_path)\n",
    "        \n",
    "    def vectorize_data(self) -> None:\n",
    "        \"\"\"vectorize the splited dataset and dump vectorizer model\n",
    "        \"\"\"\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        \n",
    "        logger.info(f\"Load data train in {self.config.input_train_path}.\")\n",
    "        X_train = joblib.load(self.config.input_train_path)\n",
    "        \n",
    "        logger.info(f\"Load data test in {self.config.input_test_path}.\")\n",
    "        X_test = joblib.load(self.config.input_test_path)\n",
    "        \n",
    "        logger.info(f\"Vectorize the data.\")\n",
    "        X_train_vec = vectorizer.fit_transform(X_train)\n",
    "        X_test_vec = vectorizer.transform(X_test)\n",
    "        \n",
    "        logger.info(f\"Dump the vectorized data.\")\n",
    "        joblib.dump(X_train_vec, self.config.vectorized_train_path)\n",
    "        joblib.dump(X_test_vec, self.config.vectorized_test_path)\n",
    "        \n",
    "        logger.info(f\"Creating {self.config.model_dir} directory.\")\n",
    "        model_dir = str(self.config.model_dir)\n",
    "        os.makedirs(model_dir, exist_ok=True)\n",
    "        \n",
    "        logger.info(f\"Save the vectorizer model.\")\n",
    "        joblib.dump(vectorizer, self.config.vectorizer_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dump the Data Train and Data Test\n",
    "\n",
    "This code in `src/LazadaIDReview/pipeline/step_02_preprocessing.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-03 20:37:50,329: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
      "[2024-07-03 20:37:50,334: INFO: common: yaml file: metrics/params.yaml loaded successfully]\n",
      "[2024-07-03 20:37:50,336: INFO: common: created directory at: artifacts]\n",
      "[2024-07-03 20:37:50,339: INFO: common: created directory at: artifacts/data]\n",
      "[2024-07-03 20:37:50,341: INFO: 944171181: Read reviews file.]\n",
      "[2024-07-03 20:37:50,802: INFO: 944171181: Split reviews file to data train and test.]\n",
      "[2024-07-03 20:37:50,811: INFO: 944171181: Dump data train into artifacts/data/X_train.pkl directory.]\n",
      "[2024-07-03 20:37:50,849: INFO: 944171181: Dump data test into artifacts/data/X_test.pkl directory.]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    dump_data_config = config.get_dump_data_config()\n",
    "    data_ingestion = Preprocessing(config=dump_data_config)\n",
    "    data_ingestion.dump_data()\n",
    "except Exception as e:\n",
    "    logger.error(e)\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Debug**: Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52942     Keasyikan menikmati fitur2 dan keindahan tv yg...\n",
       "180906    Barang bagus. Sesuai gambar. Dapat berfungsi d...\n",
       "42906     Joss, produk recommended tinggal disambung ke ...\n",
       "78698                                                  ok..\n",
       "107577    Barang sesuai pesanan, respon dan pengiriman c...\n",
       "                                ...                        \n",
       "144839                                      Mantap betul...\n",
       "140798          manstabs barang sesuai harga semoga awet...\n",
       "130589                                          Recomended!\n",
       "62207                                      barang sesuai...\n",
       "104402    Alhamdllah mendarat dg slmat..packing rapi pen...\n",
       "Name: reviewContent, Length: 21405, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = joblib.load(dump_data_config.input_train_path)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52942     5\n",
       "180906    5\n",
       "42906     5\n",
       "78698     5\n",
       "107577    5\n",
       "         ..\n",
       "144839    5\n",
       "140798    5\n",
       "130589    5\n",
       "62207     5\n",
       "104402    5\n",
       "Name: rating, Length: 21405, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = joblib.load(dump_data_config.output_train_path)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18124        pengiriman masuk standar range, pengemasan ok.\n",
       "72091                            barang da sampai..mantab👍👍\n",
       "141328                                             mantabbb\n",
       "121808                          Ini berapa inci ya layarnya\n",
       "185155                                               mantap\n",
       "                                ...                        \n",
       "10271                                        ga bisa dipake\n",
       "127624       Alhamdulillah tv nya bagus dan paking nya rapi\n",
       "49817     barang sudah sampai dengan selamat, tapi tidak...\n",
       "501       Produk sesuai dengan deskripsi, sampai saat in...\n",
       "58544                                 BARANG SESUAI PESANAN\n",
       "Name: reviewContent, Length: 85624, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = joblib.load(dump_data_config.input_test_path)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18124     4\n",
       "72091     5\n",
       "141328    5\n",
       "121808    3\n",
       "185155    5\n",
       "         ..\n",
       "10271     1\n",
       "127624    5\n",
       "49817     5\n",
       "501       5\n",
       "58544     4\n",
       "Name: rating, Length: 85624, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = joblib.load(dump_data_config.output_test_path)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize the Data Train and Data Test\n",
    "\n",
    "This code in `src/LazadaIDReview/pipeline/step_02_preprocessing.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-03 20:40:04,993: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
      "[2024-07-03 20:40:04,997: INFO: common: yaml file: metrics/params.yaml loaded successfully]\n",
      "[2024-07-03 20:40:04,998: INFO: common: created directory at: artifacts]\n",
      "[2024-07-03 20:40:05,000: INFO: common: created directory at: artifacts/preprocessing]\n",
      "[2024-07-03 20:40:05,001: INFO: 944171181: Load data train in artifacts/data/X_train.pkl.]\n",
      "[2024-07-03 20:40:05,032: INFO: 944171181: Load data test in artifacts/data/X_test.pkl.]\n",
      "[2024-07-03 20:40:05,154: INFO: 944171181: Vectorize the data.]\n",
      "[2024-07-03 20:40:06,077: INFO: 944171181: Dump the vectorized data.]\n",
      "[2024-07-03 20:40:06,096: INFO: 944171181: Creating artifacts/models directory.]\n",
      "[2024-07-03 20:40:06,098: INFO: 944171181: Save the vectorizer model.]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    preprocessing_config = config.get_preprocessing_data_config()\n",
    "    preprocessing = Preprocessing(config=preprocessing_config)\n",
    "    preprocessing.vectorize_data()\n",
    "except Exception as e:\n",
    "    logger.error(e)\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Debug**: Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<21405x13745 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 251629 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vec = joblib.load(preprocessing_config.vectorized_train_path)\n",
    "X_train_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<85624x13745 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 984786 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_vec = joblib.load(preprocessing_config.vectorized_test_path)\n",
    "X_test_vec"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_lzd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
